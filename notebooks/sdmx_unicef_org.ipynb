{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import logging\n",
    "from dfpp.transformation.sources.unicef_org.retrieve import (\n",
    "    get_indicator,\n",
    "    get_sdmx_client,\n",
    "    get_dataflow_codebook,\n",
    ")\n",
    "from dfpp.transformation.sources.unicef_org.transform import transform\n",
    "from dfpp.publishing import publish_series\n",
    "from dfpp.geo_utils import get_iso3_to_official_name_map\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(module)s - %(message)s\",\n",
    "    handlers=[logging.StreamHandler()],\n",
    ")\n",
    "ISO_3_MAP = await get_iso3_to_official_name_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_sdmx_client()\n",
    "dataflow_id = \"GLOBAL_DATAFLOW\"\n",
    "df_indicators, df_dimensions, df_attrributes = get_dataflow_codebook(\n",
    "    client, dataflow_id=dataflow_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_series = []\n",
    "indicators_processed = 0\n",
    "\n",
    "parent_code = df_indicators[df_indicators.parent == \"\"].indicator_code.unique().tolist()\n",
    "\n",
    "indicator_codes = df_indicators.indicator_code.unique().tolist()\n",
    "print(\"Indicator codes to query:\", len(indicator_codes))\n",
    "for indicator_id in tqdm(indicator_codes):\n",
    "    if indicator_id in parent_code:\n",
    "        continue\n",
    "    logging.info(indicator_id)\n",
    "    try:\n",
    "        df_source = get_indicator(\n",
    "            client, dataflow_id=dataflow_id, indicator_id=indicator_id\n",
    "        )\n",
    "        if \"REF_PERIOD\" in df_source:\n",
    "            logging.debug(f\"{indicator_id} has REF_PERIOD\")\n",
    "\n",
    "        df = df_source.copy()\n",
    "        df = transform(\n",
    "            df_indicator=df,\n",
    "            df_dimensions=df_dimensions,\n",
    "            df_attributes=df_attrributes,\n",
    "            df_indicators=df_indicators,\n",
    "            iso_3_map=ISO_3_MAP,\n",
    "        )\n",
    "        publish_series(indicator_id, df)\n",
    "        indicators_processed += 1\n",
    "    except Exception as e:\n",
    "        logging.error(indicator_id, str(e))\n",
    "        failed_series.append((indicator_id, e))\n",
    "    logging.info(f\"error count: {len(failed_series)}\")\n",
    "    logging.info(f\"indicators_processed: {indicators_processed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(failed_series) == 0, print(failed_series)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "undp_dfx_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
