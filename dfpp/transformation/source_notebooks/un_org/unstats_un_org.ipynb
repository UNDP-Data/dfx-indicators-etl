{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/mykhailoslukvin/repo/dv-data-pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mykhailoslukvin/.local/lib/python3.11/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cd ../../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "from io import BytesIO\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from pprint import pprint as print\n",
    "\n",
    "import aiohttp\n",
    "import country_converter as coco\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm.asyncio import tqdm_asyncio\n",
    "\n",
    "from dfpp.storage import StorageManager\n",
    "from dfpp.transformation.column_name_template import SexEnum\n",
    "\n",
    "cc = coco.CountryConverter()\n",
    "\n",
    "MAX_CONCURRENCY = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "async with StorageManager() as storage_manager:\n",
    "    path = os.path.join(storage_manager.utilities_path, \"sep5_country_lookup.xlsx\")\n",
    "    data = await storage_manager.read_blob(path=path)\n",
    "    df_country_map = pd.read_excel(BytesIO(data), sheet_name=\"country_lookup\")\n",
    "    df_region_map = pd.read_excel(BytesIO(data), sheet_name=\"region_lookup\")\n",
    "\n",
    "df_country_map = df_country_map[df_country_map[\"Numeric code\"].notna()]\n",
    "df_country_map[\"Numeric code\"] = df_country_map[\"Numeric code\"].astype(int)\n",
    "\n",
    "df_region_map = df_region_map[df_region_map[\"Numeric code\"].notna()]\n",
    "df_region_map[\"Numeric code\"] = df_region_map[\"Numeric code\"].astype(int)\n",
    "\n",
    "iso_3_region = dict(df_region_map[[\"Numeric code\", \"Alpha-3 code\"]].values)\n",
    "iso_3_country = dict(df_country_map[[\"Numeric code\", \"iso3\"]].values)\n",
    "\n",
    "iso_3_country.update(iso_3_region)\n",
    "\n",
    "iso_3_map = iso_3_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_remap = {\n",
    "    \"BOTHSEX\": SexEnum.BOTH.value,\n",
    "    \"MALE\": SexEnum.MALE.value,\n",
    "    \"FEMALE\": SexEnum.FEMALE.value,\n",
    "}\n",
    "\n",
    "age_remap = {\"ALLAGE\", \"all\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indicators():\n",
    "    url = \"https://unstats.un.org/sdgapi/v1/sdg/CompareTrends/GetDisaggregatedGlobalAndRegional\"\n",
    "\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "\n",
    "    response = requests.post(url, headers=headers)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    data = response.json()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicators = get_indicators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_codes = set([i[\"seriesCode\"] for i in indicators])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_data(session, series_id, semaphore):\n",
    "    url = f\"https://unstats.un.org/sdgapi/v1/sdg/Series/Data\"\n",
    "    params = {\"seriesCode\": series_id, \"page\": 1, \"pageSize\": 10000000}\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "\n",
    "    async with semaphore:\n",
    "        async with session.get(url, headers=headers, params=params) as response:\n",
    "            response.raise_for_status()\n",
    "            return await response.json()\n",
    "\n",
    "\n",
    "async def process_series(series_id, session, semaphore):\n",
    "    year_data = await fetch_data(session, series_id, semaphore)\n",
    "\n",
    "    dimensions = [d[\"id\"] for d in year_data[\"dimensions\"]]\n",
    "    size = year_data[\"totalElements\"]\n",
    "    return series_id, year_data[\"data\"], dimensions, size\n",
    "\n",
    "\n",
    "async def get_series_data_and_dimensions(\n",
    "    series_codes, max_concurrent_requests=MAX_CONCURRENCY\n",
    "):\n",
    "    semaphore = asyncio.Semaphore(max_concurrent_requests)\n",
    "    series_data_map = {}\n",
    "    series_map = defaultdict(dict)\n",
    "\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for row in series_codes:\n",
    "            series_id = row\n",
    "            tasks.append(process_series(series_id, session, semaphore))\n",
    "\n",
    "        results = await asyncio.gather(*tasks)\n",
    "\n",
    "        for series_id, data, dimensions, size in results:\n",
    "            series_data_map[series_id] = data\n",
    "            series_map[series_id][\"dimensions\"] = dimensions\n",
    "            series_map[series_id][\"totalElements\"] = size\n",
    "\n",
    "    return series_data_map, series_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/426 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Series description: Alcohol consumption per capita (aged 15 years and older) '\n",
      " 'within a calendar year (litres of pure alcohol)')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/l11h93nn4s542l1h1yzw34980000gn/T/ipykernel_5610/1393530018.py:48: FutureWarning: Series.replace without 'value' and with non-dict-like 'to_replace' is deprecated and will raise in a future version. Explicitly specify the new values instead.\n",
      "  df_selection[\"age\"] = df_selection[\"age\"].replace(age_remap)\n",
      "  0%|          | 1/426 [00:18<2:12:52, 18.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Series description: Freight volume, by mode of transport (tonne kilometres)'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/426 [00:28<1:35:35, 13.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Series description: Annual growth rate of real GDP per capita (%)'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/426 [00:58<2:17:46, 19.54s/it]\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m series_id \u001b[38;5;129;01min\u001b[39;00m tqdm(series_codes):\n\u001b[0;32m----> 2\u001b[0m     series_data_map, dimension_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m get_series_data_and_dimensions([series_id])\n\u001b[1;32m      3\u001b[0m     df_source \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(series_data_map[series_id])\n\u001b[1;32m      4\u001b[0m     df \u001b[38;5;241m=\u001b[39m df_source\u001b[38;5;241m.\u001b[39mcopy()\n",
      "Cell \u001b[0;32mIn[7], line 33\u001b[0m, in \u001b[0;36mget_series_data_and_dimensions\u001b[0;34m(series_codes, max_concurrent_requests)\u001b[0m\n\u001b[1;32m     30\u001b[0m     series_id \u001b[38;5;241m=\u001b[39m row\n\u001b[1;32m     31\u001b[0m     tasks\u001b[38;5;241m.\u001b[39mappend(process_series(series_id, session, semaphore))\n\u001b[0;32m---> 33\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m series_id, data, dimensions, size \u001b[38;5;129;01min\u001b[39;00m results:\n\u001b[1;32m     36\u001b[0m     series_data_map[series_id] \u001b[38;5;241m=\u001b[39m data\n",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m, in \u001b[0;36mprocess_series\u001b[0;34m(series_id, session, semaphore)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_series\u001b[39m(series_id, session, semaphore):\n\u001b[0;32m---> 13\u001b[0m     year_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m fetch_data(session, series_id, semaphore)\n\u001b[1;32m     15\u001b[0m     dimensions \u001b[38;5;241m=\u001b[39m [d[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m year_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimensions\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m     16\u001b[0m     size \u001b[38;5;241m=\u001b[39m year_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtotalElements\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mfetch_data\u001b[0;34m(session, series_id, semaphore)\u001b[0m\n\u001b[1;32m      4\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m semaphore:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mwith\u001b[39;00m session\u001b[38;5;241m.\u001b[39mget(url, headers\u001b[38;5;241m=\u001b[39mheaders, params\u001b[38;5;241m=\u001b[39mparams) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m      8\u001b[0m         response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/anaconda3/envs/undp_dfx_pipeline/lib/python3.11/site-packages/aiohttp/client.py:1197\u001b[0m, in \u001b[0;36m_BaseRequestContextManager.__aenter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__aenter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _RetType:\n\u001b[0;32m-> 1197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coro\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resp\n",
      "File \u001b[0;32m~/anaconda3/envs/undp_dfx_pipeline/lib/python3.11/site-packages/aiohttp/client.py:608\u001b[0m, in \u001b[0;36mClientSession._request\u001b[0;34m(self, method, str_or_url, params, data, json, cookies, headers, skip_auto_headers, auth, allow_redirects, max_redirects, compress, chunked, expect100, raise_for_status, read_until_eof, proxy, proxy_auth, timeout, verify_ssl, fingerprint, ssl_context, ssl, server_hostname, proxy_headers, trace_request_ctx, read_bufsize, auto_decompress, max_line_size, max_field_size)\u001b[0m\n\u001b[1;32m    606\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m req\u001b[38;5;241m.\u001b[39msend(conn)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstart(conn)\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m     resp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/undp_dfx_pipeline/lib/python3.11/site-packages/aiohttp/client_reqrep.py:976\u001b[0m, in \u001b[0;36mClientResponse.start\u001b[0;34m(self, connection)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    975\u001b[0m     protocol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_protocol\n\u001b[0;32m--> 976\u001b[0m     message, payload \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m protocol\u001b[38;5;241m.\u001b[39mread()  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m http\u001b[38;5;241m.\u001b[39mHttpProcessingError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    978\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ClientResponseError(\n\u001b[1;32m    979\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_info,\n\u001b[1;32m    980\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    983\u001b[0m         headers\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    984\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/undp_dfx_pipeline/lib/python3.11/site-packages/aiohttp/streams.py:640\u001b[0m, in \u001b[0;36mDataQueue.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loop\u001b[38;5;241m.\u001b[39mcreate_future()\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 640\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (asyncio\u001b[38;5;241m.\u001b[39mCancelledError, asyncio\u001b[38;5;241m.\u001b[39mTimeoutError):\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_waiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for series_id in tqdm(series_codes):\n",
    "    series_data_map, dimension_map = await get_series_data_and_dimensions([series_id])\n",
    "    df_source = pd.DataFrame(series_data_map[series_id])\n",
    "    df = df_source.copy()\n",
    "\n",
    "    assert df.shape[0] > 0, \"DataFrame is empty\"\n",
    "\n",
    "    assert (\n",
    "        df.series.value_counts(dropna=False).shape[0] == 1\n",
    "    ), \"Multiple series values found\"\n",
    "\n",
    "    print(f\"Series description: {df.seriesDescription.iloc[0]}\")\n",
    "\n",
    "    assert (\n",
    "        df.shape[0] == dimension_map[series_id][\"totalElements\"]\n",
    "    ), \"Shape mismatch with expected dimensions\"\n",
    "\n",
    "    df_dimensions = pd.json_normalize(df[\"dimensions\"])\n",
    "    df_attributes = pd.json_normalize(df[\"attributes\"])\n",
    "\n",
    "    df = pd.concat([df.drop(columns=[\"dimensions\"]), df_dimensions], axis=1)\n",
    "    df = pd.concat([df.drop(columns=[\"attributes\"]), df_attributes], axis=1)\n",
    "\n",
    "    df.rename(\n",
    "        columns={\n",
    "            \"geoAreaCode\": \"alpha_3_code\",\n",
    "            \"geoAreaName\": \"country_or_area\",\n",
    "            \"timePeriodStart\": \"year\",\n",
    "        },\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "    original_dimension_columns = df_dimensions.columns\n",
    "    dimension_columns = original_dimension_columns.str.lower().str.replace(\n",
    "        \"\\s\", \"_\", regex=True\n",
    "    )\n",
    "    dimension_column_rename_map = dict(\n",
    "        zip(original_dimension_columns, dimension_columns)\n",
    "    )\n",
    "\n",
    "    df.rename(columns=dimension_column_rename_map, inplace=True)\n",
    "\n",
    "    df_selection = df.copy()[\n",
    "        [\"alpha_3_code\", \"country_or_area\", \"year\"] + dimension_columns.tolist()\n",
    "    ]\n",
    "\n",
    "    if \"age\" in df_selection.columns:\n",
    "        df_selection[\"age\"] = df_selection[\"age\"].replace(age_remap)\n",
    "\n",
    "    if \"sex\" in df_selection.columns:\n",
    "        df_selection[\"sex\"] = df_selection[\"sex\"].replace(sex_remap)\n",
    "\n",
    "    df_selection[\"alpha_3_code\"] = df_selection[\"alpha_3_code\"].astype(int)\n",
    "    df_selection[\"alpha_3_code\"] = df_selection[\"alpha_3_code\"].replace(iso_3_map)\n",
    "\n",
    "    with io.BytesIO() as output_buffer:\n",
    "        df_selection.to_excel(output_buffer, index=False, engine=\"openpyxl\")\n",
    "        output_buffer.seek(0)\n",
    "\n",
    "        async with StorageManager() as storage_manager:\n",
    "            path_to_save = os.path.join(\n",
    "                storage_manager.test_path, \"unstats_un_org\", f\"{series_id}.xlsx\"\n",
    "            )\n",
    "            blob_client = storage_manager.container_client.get_blob_client(\n",
    "                blob=path_to_save\n",
    "            )\n",
    "\n",
    "            await blob_client.upload_blob(\n",
    "                data=output_buffer.getvalue(),\n",
    "                overwrite=True,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def process_series_id(series_id, age_remap, sex_remap, iso_3_map, storage_manager, semaphore):\n",
    "    async with semaphore:\n",
    "        series_data_map, dimension_map = await get_series_data_and_dimensions([series_id])\n",
    "        df_source = pd.DataFrame(series_data_map[series_id])\n",
    "        df = df_source.copy()\n",
    "\n",
    "        assert df.shape[0] > 0, \"DataFrame is empty\"\n",
    "        assert df.series.value_counts(dropna=False).shape[0] == 1, \"Multiple series values found\"\n",
    "\n",
    "        print(f\"Series description: {df.seriesDescription.iloc[0]}\")\n",
    "\n",
    "        assert df.shape[0] == dimension_map[series_id][\"totalElements\"], \"Shape mismatch with expected dimensions\"\n",
    "\n",
    "        df_dimensions = pd.json_normalize(df[\"dimensions\"])\n",
    "        df_attributes = pd.json_normalize(df[\"attributes\"])\n",
    "\n",
    "        df = pd.concat([df.drop(columns=[\"dimensions\"]), df_dimensions], axis=1)\n",
    "        df = pd.concat([df.drop(columns=[\"attributes\"]), df_attributes], axis=1)\n",
    "\n",
    "        df.rename(\n",
    "            columns={\n",
    "                \"geoAreaCode\": \"alpha_3_code\",\n",
    "                \"geoAreaName\": \"country_or_area\",\n",
    "                \"timePeriodStart\": \"year\",\n",
    "            },\n",
    "            inplace=True,\n",
    "        )\n",
    "\n",
    "        original_dimension_columns = df_dimensions.columns\n",
    "        dimension_columns = original_dimension_columns.str.lower().str.replace(\"\\s\", \"_\", regex=True)\n",
    "        dimension_column_rename_map = dict(zip(original_dimension_columns, dimension_columns))\n",
    "\n",
    "        df.rename(columns=dimension_column_rename_map, inplace=True)\n",
    "\n",
    "        df_selection = df.copy()[[\"alpha_3_code\", \"country_or_area\", \"year\"] + dimension_columns.tolist()]\n",
    "\n",
    "        if \"age\" in df_selection.columns:\n",
    "            df_selection[\"age\"] = df_selection[\"age\"].replace(age_remap)\n",
    "\n",
    "        if \"sex\" in df_selection.columns:\n",
    "            df_selection[\"sex\"] = df_selection[\"sex\"].replace(sex_remap)\n",
    "\n",
    "        df_selection[\"alpha_3_code\"] = df_selection[\"alpha_3_code\"].astype(int)\n",
    "        df_selection[\"alpha_3_code\"] = df_selection[\"alpha_3_code\"].replace(iso_3_map)\n",
    "\n",
    "        with io.BytesIO() as output_buffer:\n",
    "            df_selection.to_excel(output_buffer, index=False, engine=\"openpyxl\")\n",
    "            output_buffer.seek(0)\n",
    "\n",
    "            path_to_save = os.path.join(storage_manager.test_path, \"unstats_un_org\", f\"{series_id}.xlsx\")\n",
    "            blob_client = storage_manager.container_client.get_blob_client(blob=path_to_save)\n",
    "\n",
    "            await blob_client.upload_blob(data=output_buffer.getvalue(), overwrite=True)\n",
    "\n",
    "\n",
    "async def process_all_series(series_codes, age_remap, sex_remap, iso_3_map, max_concurrent_tasks=MAX_CONCURRENCY):\n",
    "   \n",
    "    semaphore = asyncio.Semaphore(max_concurrent_tasks)\n",
    "\n",
    "    async with StorageManager() as storage_manager:\n",
    "        tasks = [\n",
    "            process_series_id(series_id, age_remap, sex_remap, iso_3_map, storage_manager, semaphore)\n",
    "            for series_id in series_codes\n",
    "        ]\n",
    "       \n",
    "        for task in tqdm_asyncio.as_completed(tasks):\n",
    "            await task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/426 [00:12<?, ?it/s]\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m process_all_series(series_codes, age_remap, sex_remap, iso_3_map, max_concurrent_tasks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[23], line 67\u001b[0m, in \u001b[0;36mprocess_all_series\u001b[0;34m(series_codes, age_remap, sex_remap, iso_3_map, max_concurrent_tasks)\u001b[0m\n\u001b[1;32m     61\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     62\u001b[0m     process_series_id(series_id, age_remap, sex_remap, iso_3_map, storage_manager, semaphore)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m series_id \u001b[38;5;129;01min\u001b[39;00m series_codes\n\u001b[1;32m     64\u001b[0m ]\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m tqdm_asyncio\u001b[38;5;241m.\u001b[39mas_completed(tasks):\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m task\n",
      "File \u001b[0;32m~/anaconda3/envs/undp_dfx_pipeline/lib/python3.11/asyncio/tasks.py:611\u001b[0m, in \u001b[0;36mas_completed.<locals>._wait_for_one\u001b[0;34m()\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wait_for_one\u001b[39m():\n\u001b[0;32m--> 611\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m done\u001b[38;5;241m.\u001b[39mget()\n\u001b[1;32m    612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    613\u001b[0m         \u001b[38;5;66;03m# Dummy value from _on_timeout().\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTimeoutError\n",
      "File \u001b[0;32m~/anaconda3/envs/undp_dfx_pipeline/lib/python3.11/asyncio/queues.py:158\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getters\u001b[38;5;241m.\u001b[39mappend(getter)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m getter\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     getter\u001b[38;5;241m.\u001b[39mcancel()  \u001b[38;5;66;03m# Just in case getter is not done yet.\u001b[39;00m\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Series description: Proportion of women who make their own informed '\n",
      " 'decisions regarding contraceptive use (% of women aged 15-49 years)')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/l11h93nn4s542l1h1yzw34980000gn/T/ipykernel_5610/2778916810.py:38: FutureWarning: Series.replace without 'value' and with non-dict-like 'to_replace' is deprecated and will raise in a future version. Explicitly specify the new values instead.\n",
      "  df_selection[\"age\"] = df_selection[\"age\"].replace(age_remap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Series description: Extent to which countries have laws and regulations that '\n",
      " 'guarantee full and equal access to women and men aged 15 years and older to '\n",
      " 'sexual and reproductive health care, information and education (%)')\n",
      "('Series description: Degree of integrated water resources management '\n",
      " 'implementation, management instruments (%)')\n",
      "('Series description: Beach litter originating from national land-based '\n",
      " 'sources that ends in the beach (%)')\n",
      "('Series description: Bribery incidence (% of firms experiencing at least one '\n",
      " 'bribe payment request)')\n",
      "('Series description: Proportion of individuals who own a mobile telephone, by '\n",
      " 'sex (%)')\n",
      "('Series description: Alcohol consumption per capita (aged 15 years and older) '\n",
      " 'within a calendar year (litres of pure alcohol)')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/l11h93nn4s542l1h1yzw34980000gn/T/ipykernel_5610/2778916810.py:38: FutureWarning: Series.replace without 'value' and with non-dict-like 'to_replace' is deprecated and will raise in a future version. Explicitly specify the new values instead.\n",
      "  df_selection[\"age\"] = df_selection[\"age\"].replace(age_remap)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Series description: Number of countries with national adaptation plans '\n",
      " '(Number)')\n",
      "('Series description: Gross receipts by developing countries of official '\n",
      " 'sustainable development grants (millions of United States dollars)')\n",
      "('Series description: Degree of application of a '\n",
      " 'legal/regulatory/policy/institutional framework which recognizes and '\n",
      " 'protects access rights for small-scale fisheries (level of implementation: 1 '\n",
      " 'lowest to 5 highest)')\n",
      "('Series description: Total official flows for infrastructure, by recipient '\n",
      " 'countries (millions of constant 2022 United States dollars)')\n"
     ]
    }
   ],
   "source": [
    "await process_all_series(series_codes, age_remap, sex_remap, iso_3_map, max_concurrent_tasks=MAX_CONCURRENCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "undp_dfx_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
